{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02acecec",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK 03 - OPTIMISATION DU MOD√àLE POUR RASPBERRY PI\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "## ‚ö° Optimisation du Mod√®le pour D√©ploiement Edge\n",
    "# \n",
    "# Ce notebook optimise le mod√®le pour:\n",
    "# 1. Quantification (INT8, FP16)\n",
    "# 2. Pruning (√©lagage des poids)\n",
    "# 3. Conversion TensorFlow Lite\n",
    "# 4. Optimisation pour Coral Edge TPU\n",
    "# 5. Benchmark de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3286de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "!pip install -q tensorflow tensorflow-model-optimization\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le entra√Æn√©\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "MODEL_DIR = Path('/content/drive/MyDrive/drone-agri-ai/models')\n",
    "OUTPUT_DIR = Path('/content/optimized_models')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Charger le mod√®le Keras\n",
    "model = keras.models.load_model(MODEL_DIR / 'plant_model.keras')\n",
    "model.summary()\n",
    "\n",
    "# Cr√©er un dataset repr√©sentatif pour calibration\n",
    "DATA_DIR = Path('/content/drive/MyDrive/drone-agri-ai/data/train')\n",
    "\n",
    "def create_representative_dataset(data_dir, num_samples=200):\n",
    "    \"\"\"Cr√©e un dataset pour la calibration de quantification\"\"\"\n",
    "    images = []\n",
    "    \n",
    "    for class_dir in list(data_dir.iterdir())[:20]:  # 20 classes\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        for img_path in list(class_dir.glob('*.jpg'))[:10]:  # 10 images/classe\n",
    "            img = tf.io.read_file(str(img_path))\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = tf.cast(img, tf.float32) / 255.0\n",
    "            # Normalisation ImageNet\n",
    "            mean = tf.constant([0.485, 0.456, 0.406])\n",
    "            std = tf.constant([0.229, 0.224, 0.225])\n",
    "            img = (img - mean) / std\n",
    "            images.append(img.numpy())\n",
    "            \n",
    "            if len(images) >= num_samples:\n",
    "                break\n",
    "        if len(images) >= num_samples:\n",
    "            break\n",
    "    \n",
    "    return np.array(images)\n",
    "\n",
    "print(\"Cr√©ation du dataset repr√©sentatif...\")\n",
    "representative_data = create_representative_dataset(DATA_DIR)\n",
    "print(f\"Dataset: {representative_data.shape}\")\n",
    "\n",
    "# Conversion TFLite de base (FP32)\n",
    "print(\"üì¶ Conversion TFLite FP32...\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_fp32 = converter.convert()\n",
    "\n",
    "# Sauvegarder\n",
    "fp32_path = OUTPUT_DIR / 'plant_model_fp32.tflite'\n",
    "with open(fp32_path, 'wb') as f:\n",
    "    f.write(tflite_fp32)\n",
    "\n",
    "print(f\"‚úÖ FP32: {len(tflite_fp32) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Conversion TFLite FP16 (demi-pr√©cision)\n",
    "print(\"üì¶ Conversion TFLite FP16...\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16 = converter.convert()\n",
    "\n",
    "fp16_path = OUTPUT_DIR / 'plant_model_fp16.tflite'\n",
    "with open(fp16_path, 'wb') as f:\n",
    "    f.write(tflite_fp16)\n",
    "\n",
    "print(f\"‚úÖ FP16: {len(tflite_fp16) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Conversion TFLite INT8 (quantification compl√®te)\n",
    "print(\"üì¶ Conversion TFLite INT8...\")\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    \"\"\"G√©n√©rateur pour la calibration\"\"\"\n",
    "    for i in range(min(100, len(representative_data))):\n",
    "        yield [representative_data[i:i+1].astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "try:\n",
    "    tflite_int8 = converter.convert()\n",
    "    \n",
    "    int8_path = OUTPUT_DIR / 'plant_model_int8.tflite'\n",
    "    with open(int8_path, 'wb') as f:\n",
    "        f.write(tflite_int8)\n",
    "    \n",
    "    print(f\"‚úÖ INT8: {len(tflite_int8) / 1024 / 1024:.2f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur INT8: {e}\")\n",
    "    tflite_int8 = None\n",
    "\n",
    "# Quantification dynamique\n",
    "print(\"üì¶ Conversion avec quantification dynamique...\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_dynamic = converter.convert()\n",
    "\n",
    "dynamic_path = OUTPUT_DIR / 'plant_model_dynamic.tflite'\n",
    "with open(dynamic_path, 'wb') as f:\n",
    "    f.write(tflite_dynamic)\n",
    "\n",
    "print(f\"‚úÖ Dynamic: {len(tflite_dynamic) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac50cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le Pruning au mod√®le\n",
    "print(\"‚úÇÔ∏è Application du Pruning...\")\n",
    "\n",
    "# Recr√©er le mod√®le avec pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.20,\n",
    "        final_sparsity=0.70,\n",
    "        begin_step=0,\n",
    "        end_step=1000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Appliquer aux couches Dense uniquement\n",
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, keras.layers.Dense):\n",
    "        return prune_low_magnitude(layer, **pruning_params)\n",
    "    return layer\n",
    "\n",
    "# Cloner le mod√®le avec pruning\n",
    "model_for_pruning = keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pruning configur√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab88294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark des mod√®les\n",
    "print(\"‚è±Ô∏è Benchmark des mod√®les...\")\n",
    "\n",
    "def benchmark_tflite(model_path, num_runs=50):\n",
    "    \"\"\"Benchmark un mod√®le TFLite\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(model_path))\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Pr√©parer l'entr√©e\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_dtype = input_details[0]['dtype']\n",
    "    \n",
    "    if input_dtype == np.uint8:\n",
    "        input_data = np.random.randint(0, 255, input_shape).astype(np.uint8)\n",
    "    else:\n",
    "        input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start = time.perf_counter()\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        times.append((time.perf_counter() - start) * 1000)\n",
    "    \n",
    "    return {\n",
    "        'mean_ms': np.mean(times),\n",
    "        'std_ms': np.std(times),\n",
    "        'min_ms': np.min(times),\n",
    "        'max_ms': np.max(times),\n",
    "        'fps': 1000 / np.mean(times)\n",
    "    }\n",
    "\n",
    "# Benchmarker tous les mod√®les\n",
    "results = {}\n",
    "for name, path in [\n",
    "    ('FP32', fp32_path),\n",
    "    ('FP16', fp16_path),\n",
    "    ('Dynamic', dynamic_path),\n",
    "]:\n",
    "    if path.exists():\n",
    "        print(f\"Benchmark {name}...\")\n",
    "        results[name] = benchmark_tflite(path)\n",
    "        results[name]['size_mb'] = path.stat().st_size / 1024 / 1024\n",
    "\n",
    "if int8_path.exists():\n",
    "    print(\"Benchmark INT8...\")\n",
    "    results['INT8'] = benchmark_tflite(int8_path)\n",
    "    results['INT8']['size_mb'] = int8_path.stat().st_size / 1024 / 1024\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä R√âSULTATS DU BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, stats in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Taille: {stats['size_mb']:.2f} MB\")\n",
    "    print(f\"  Temps: {stats['mean_ms']:.2f} ¬± {stats['std_ms']:.2f} ms\")\n",
    "    print(f\"  FPS: {stats['fps']:.1f}\")\n",
    "\n",
    "# Graphique comparatif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "names = list(results.keys())\n",
    "sizes = [results[n]['size_mb'] for n in names]\n",
    "times = [results[n]['mean_ms'] for n in names]\n",
    "fps = [results[n]['fps'] for n in names]\n",
    "\n",
    "# Taille\n",
    "axes[0].bar(names, sizes, color='steelblue')\n",
    "axes[0].set_ylabel('Taille (MB)')\n",
    "axes[0].set_title('Taille du mod√®le')\n",
    "\n",
    "# Temps\n",
    "axes[1].bar(names, times, color='coral')\n",
    "axes[1].set_ylabel('Temps (ms)')\n",
    "axes[1].set_title('Temps d\\'inf√©rence')\n",
    "\n",
    "# FPS\n",
    "axes[2].bar(names, fps, color='forestgreen')\n",
    "axes[2].set_ylabel('FPS')\n",
    "axes[2].set_title('Images par seconde')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'benchmark_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le meilleur mod√®le pour Raspberry Pi\n",
    "print(\"\\nüéØ RECOMMANDATION POUR RASPBERRY PI\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Le mod√®le FP16 offre g√©n√©ralement le meilleur compromis\n",
    "best_model = 'FP16'\n",
    "best_path = fp16_path\n",
    "\n",
    "print(f\"\"\"\n",
    "Mod√®le recommand√©: {best_model}\n",
    "- Taille: {results[best_model]['size_mb']:.2f} MB\n",
    "- Temps: {results[best_model]['mean_ms']:.2f} ms\n",
    "- FPS: {results[best_model]['fps']:.1f}\n",
    "\n",
    "‚úÖ Ce mod√®le offre le meilleur compromis taille/performance\n",
    "   pour un Raspberry Pi 4.\n",
    "\n",
    "Pour Coral Edge TPU, utilisez le mod√®le INT8.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copier le mod√®le final\n",
    "!cp {best_path} /content/drive/MyDrive/drone-agri-ai/models/plant_model.tflite\n",
    "!cp {OUTPUT_DIR}/* /content/drive/MyDrive/drone-agri-ai/models/\n",
    "\n",
    "# Sauvegarder les r√©sultats du benchmark\n",
    "with open(OUTPUT_DIR / 'benchmark_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "!cp {OUTPUT_DIR}/benchmark_results.json /content/drive/MyDrive/drone-agri-ai/models/\n",
    "\n",
    "print(\"‚úÖ Mod√®les et r√©sultats copi√©s sur Google Drive!\")\n",
    "\n",
    "# T√©l√©charger le mod√®le final\n",
    "from google.colab import files\n",
    "files.download(str(best_path))\n",
    "print(f\"‚úÖ Mod√®le {best_model} t√©l√©charg√©!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
